# Crowdfunding_ETL

This project involves building an ETL (Extract, Transform, Load) pipeline using Python, Pandas, and either Python dictionary methods or regular expressions to extract and transform data from source files into CSV files. The CSV files will then be used to create an ERD (Entity-Relationship Diagram) and a table schema for a Postgres database. Finally, the CSV file data will be uploaded into the Postgres database.

## Introduction
This project aims to automate the process of extracting data from source files, transforming it into a suitable format, and loading it into a database for further analysis. The ETL pipeline consists of several steps, including data extraction, transformation using Python and Pandas, CSV file creation, ERD and table schema generation, and data loading into a Postgres database.

## Installation
To install and set up the project, follow these steps:

- Clone the repository from GitHub.
- Ensure Python and Pandas are installed on your system.
- Run the Python scripts to execute the ETL pipeline.
- Verify that the CSV files are created successfully.
- Use the CSV file data to generate the ERD and table schema.
- Create a new Postgres database and execute the SQL script to create the tables.
- Load the CSV file data into the database.

## Usage
The project can be used to automate the process of extracting, transforming, and loading data from source files into a database. Users can customize the ETL pipeline according to their specific requirements and datasets. The provided Python scripts and documentation serve as a guide for implementing similar ETL pipelines in other projects.

